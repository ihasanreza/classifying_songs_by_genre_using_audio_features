{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "3"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## Preparing the dataset\n",
    "<p>Streaming services with large music catalogs have become the main way for many people to listen to their favorite tunes. However, the huge amount of music available can make it difficult for users to find new music that matches their preferences.</p>\n",
    "<p>To help with this, streaming services have begun using methods to categorize music and provide personalized recommendations. One method involves analyzing the raw audio data of a song and scoring it based on various metrics. In this project, we will use data compiled by a research group called The Echo Nest to classify songs as either \"Hip-Hop\" or \"Rock\" without listening to any of the songs ourselves. To do this, we will clean the data, do some exploratory data visualization, and use feature reduction to feed the data into simple machine learning algorithms like decision trees and logistic regression.</p>\n",
    "<p>We will start by creating two pandas DataFrames from two different files that contain metadata and track metrics for the songs: one file is in CSV format and the other is in JSON format. These DataFrames will be merged to create features and labels (also known as \"X\" and \"y\") for classification later on.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "dc": {
     "key": "3"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4802 entries, 0 to 4801\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   track_id          4802 non-null   int64  \n",
      " 1   acousticness      4802 non-null   float64\n",
      " 2   danceability      4802 non-null   float64\n",
      " 3   energy            4802 non-null   float64\n",
      " 4   instrumentalness  4802 non-null   float64\n",
      " 5   liveness          4802 non-null   float64\n",
      " 6   speechiness       4802 non-null   float64\n",
      " 7   tempo             4802 non-null   float64\n",
      " 8   valence           4802 non-null   float64\n",
      " 9   genre_top         4802 non-null   object \n",
      "dtypes: float64(8), int64(1), object(1)\n",
      "memory usage: 412.7+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read in track metadata with genre labels\n",
    "tracks = pd.read_csv(\"datasets/fma-rock-vs-hiphop.csv\")\n",
    "\n",
    "# Read in track metrics with features\n",
    "echonest_metrics = pd.read_json(\"datasets/echonest-metrics.json\")\n",
    "\n",
    "# Merge relevant columns of tracks and echonest_metrics\n",
    "echo_tracks = echonest_metrics.merge(tracks[['track_id', 'genre_top']], on='track_id')\n",
    "\n",
    "# Check information of resultant dataframe\n",
    "echo_tracks.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "dc": {
     "key": "3"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>bit_rate</th>\n",
       "      <th>comments</th>\n",
       "      <th>composer</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>duration</th>\n",
       "      <th>favorites</th>\n",
       "      <th>genre_top</th>\n",
       "      <th>genres</th>\n",
       "      <th>...</th>\n",
       "      <th>information</th>\n",
       "      <th>interest</th>\n",
       "      <th>language_code</th>\n",
       "      <th>license</th>\n",
       "      <th>listens</th>\n",
       "      <th>lyricist</th>\n",
       "      <th>number</th>\n",
       "      <th>publisher</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135</td>\n",
       "      <td>256000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:43:26</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>837</td>\n",
       "      <td>0</td>\n",
       "      <td>Rock</td>\n",
       "      <td>[45, 58]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2484</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Father's Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136</td>\n",
       "      <td>256000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:43:35</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>509</td>\n",
       "      <td>0</td>\n",
       "      <td>Rock</td>\n",
       "      <td>[45, 58]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1948</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Peel Back The Mountain Sky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151</td>\n",
       "      <td>192000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:44:55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>Rock</td>\n",
       "      <td>[25]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>701</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Untitled 04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>152</td>\n",
       "      <td>192000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:44:58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>Rock</td>\n",
       "      <td>[25]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>637</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Untitled 11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>Arc and Sender</td>\n",
       "      <td>2008-11-26 01:45:00</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>405</td>\n",
       "      <td>5</td>\n",
       "      <td>Rock</td>\n",
       "      <td>[26]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>354</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-NoDerivatives (aka M...</td>\n",
       "      <td>424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Hundred-Year Flood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id  bit_rate  comments        composer         date_created  \\\n",
       "0       135    256000         1             NaN  2008-11-26 01:43:26   \n",
       "1       136    256000         1             NaN  2008-11-26 01:43:35   \n",
       "2       151    192000         0             NaN  2008-11-26 01:44:55   \n",
       "3       152    192000         0             NaN  2008-11-26 01:44:58   \n",
       "4       153    256000         0  Arc and Sender  2008-11-26 01:45:00   \n",
       "\n",
       "         date_recorded  duration  favorites genre_top    genres  ...  \\\n",
       "0  2008-11-26 00:00:00       837          0      Rock  [45, 58]  ...   \n",
       "1  2008-11-26 00:00:00       509          0      Rock  [45, 58]  ...   \n",
       "2                  NaN       192          0      Rock      [25]  ...   \n",
       "3                  NaN       193          0      Rock      [25]  ...   \n",
       "4  2008-11-26 00:00:00       405          5      Rock      [26]  ...   \n",
       "\n",
       "  information interest  language_code  \\\n",
       "0         NaN     2484             en   \n",
       "1         NaN     1948             en   \n",
       "2         NaN      701             en   \n",
       "3         NaN      637             en   \n",
       "4         NaN      354             en   \n",
       "\n",
       "                                             license listens  lyricist number  \\\n",
       "0  Attribution-NonCommercial-ShareAlike 3.0 Inter...    1832       NaN      0   \n",
       "1  Attribution-NonCommercial-ShareAlike 3.0 Inter...    1498       NaN      0   \n",
       "2  Attribution-NonCommercial-ShareAlike 3.0 Inter...     148       NaN      4   \n",
       "3  Attribution-NonCommercial-ShareAlike 3.0 Inter...      98       NaN     11   \n",
       "4  Attribution-NonCommercial-NoDerivatives (aka M...     424       NaN      2   \n",
       "\n",
       "   publisher tags                       title  \n",
       "0        NaN   []                Father's Day  \n",
       "1        NaN   []  Peel Back The Mountain Sky  \n",
       "2        NaN   []                 Untitled 04  \n",
       "3        NaN   []                 Untitled 11  \n",
       "4        NaN   []          Hundred-Year Flood  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.416675</td>\n",
       "      <td>0.675894</td>\n",
       "      <td>0.634476</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.177647</td>\n",
       "      <td>0.159310</td>\n",
       "      <td>165.922</td>\n",
       "      <td>0.576661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.374408</td>\n",
       "      <td>0.528643</td>\n",
       "      <td>0.817461</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>0.105880</td>\n",
       "      <td>0.461818</td>\n",
       "      <td>126.957</td>\n",
       "      <td>0.269240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.043567</td>\n",
       "      <td>0.745566</td>\n",
       "      <td>0.701470</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.373143</td>\n",
       "      <td>0.124595</td>\n",
       "      <td>100.260</td>\n",
       "      <td>0.621661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0.951670</td>\n",
       "      <td>0.658179</td>\n",
       "      <td>0.924525</td>\n",
       "      <td>0.965427</td>\n",
       "      <td>0.115474</td>\n",
       "      <td>0.032985</td>\n",
       "      <td>111.562</td>\n",
       "      <td>0.963590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134</td>\n",
       "      <td>0.452217</td>\n",
       "      <td>0.513238</td>\n",
       "      <td>0.560410</td>\n",
       "      <td>0.019443</td>\n",
       "      <td>0.096567</td>\n",
       "      <td>0.525519</td>\n",
       "      <td>114.290</td>\n",
       "      <td>0.894072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id  acousticness  danceability    energy  instrumentalness  liveness  \\\n",
       "0         2      0.416675      0.675894  0.634476          0.010628  0.177647   \n",
       "1         3      0.374408      0.528643  0.817461          0.001851  0.105880   \n",
       "2         5      0.043567      0.745566  0.701470          0.000697  0.373143   \n",
       "3        10      0.951670      0.658179  0.924525          0.965427  0.115474   \n",
       "4       134      0.452217      0.513238  0.560410          0.019443  0.096567   \n",
       "\n",
       "   speechiness    tempo   valence  \n",
       "0     0.159310  165.922  0.576661  \n",
       "1     0.461818  126.957  0.269240  \n",
       "2     0.124595  100.260  0.621661  \n",
       "3     0.032985  111.562  0.963590  \n",
       "4     0.525519  114.290  0.894072  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>genre_top</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.416675</td>\n",
       "      <td>0.675894</td>\n",
       "      <td>0.634476</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.177647</td>\n",
       "      <td>0.159310</td>\n",
       "      <td>165.922</td>\n",
       "      <td>0.576661</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.374408</td>\n",
       "      <td>0.528643</td>\n",
       "      <td>0.817461</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>0.105880</td>\n",
       "      <td>0.461818</td>\n",
       "      <td>126.957</td>\n",
       "      <td>0.269240</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.043567</td>\n",
       "      <td>0.745566</td>\n",
       "      <td>0.701470</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.373143</td>\n",
       "      <td>0.124595</td>\n",
       "      <td>100.260</td>\n",
       "      <td>0.621661</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134</td>\n",
       "      <td>0.452217</td>\n",
       "      <td>0.513238</td>\n",
       "      <td>0.560410</td>\n",
       "      <td>0.019443</td>\n",
       "      <td>0.096567</td>\n",
       "      <td>0.525519</td>\n",
       "      <td>114.290</td>\n",
       "      <td>0.894072</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153</td>\n",
       "      <td>0.988306</td>\n",
       "      <td>0.255661</td>\n",
       "      <td>0.979774</td>\n",
       "      <td>0.973006</td>\n",
       "      <td>0.121342</td>\n",
       "      <td>0.051740</td>\n",
       "      <td>90.241</td>\n",
       "      <td>0.034018</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id  acousticness  danceability    energy  instrumentalness  liveness  \\\n",
       "0         2      0.416675      0.675894  0.634476          0.010628  0.177647   \n",
       "1         3      0.374408      0.528643  0.817461          0.001851  0.105880   \n",
       "2         5      0.043567      0.745566  0.701470          0.000697  0.373143   \n",
       "3       134      0.452217      0.513238  0.560410          0.019443  0.096567   \n",
       "4       153      0.988306      0.255661  0.979774          0.973006  0.121342   \n",
       "\n",
       "   speechiness    tempo   valence genre_top  \n",
       "0     0.159310  165.922  0.576661   Hip-Hop  \n",
       "1     0.461818  126.957  0.269240   Hip-Hop  \n",
       "2     0.124595  100.260  0.621661   Hip-Hop  \n",
       "3     0.525519  114.290  0.894072   Hip-Hop  \n",
       "4     0.051740   90.241  0.034018      Rock  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(tracks.head())\n",
    "display(echonest_metrics.head())\n",
    "echo_tracks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "10"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## Creating correlation matrix\n",
    "<p>It's important to avoid using variables that are highly correlated with each other in our data, as this can lead to feature redundancy. This can have several negative consequences, such as making our model more complex and harder to interpret, increasing the risk of overfitting, and slowing down computation time when working with large datasets.</p> \n",
    "\n",
    "<p>To identify any strongly correlated features in our data, we can use the built-in functions in the <code>pandas</code> package.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "dc": {
     "key": "10"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_34105_row0_col0,#T_34105_row1_col1,#T_34105_row2_col2,#T_34105_row3_col3,#T_34105_row4_col4,#T_34105_row5_col5,#T_34105_row6_col6,#T_34105_row7_col7,#T_34105_row8_col8{\n",
       "            background-color:  #023858;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_34105_row0_col1,#T_34105_row1_col0,#T_34105_row1_col3,#T_34105_row2_col5,#T_34105_row2_col7,#T_34105_row4_col2,#T_34105_row4_col6,#T_34105_row4_col8,#T_34105_row6_col4{\n",
       "            background-color:  #fff7fb;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row0_col2{\n",
       "            background-color:  #d2d2e7;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row0_col3{\n",
       "            background-color:  #b5c4df;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row0_col4{\n",
       "            background-color:  #f5eef6;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row0_col5{\n",
       "            background-color:  #e9e5f1;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row0_col6,#T_34105_row8_col3{\n",
       "            background-color:  #d1d2e6;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row0_col7,#T_34105_row1_col7{\n",
       "            background-color:  #e1dfed;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row0_col8,#T_34105_row3_col6{\n",
       "            background-color:  #dedcec;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row1_col2{\n",
       "            background-color:  #e0dded;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row1_col4,#T_34105_row4_col1{\n",
       "            background-color:  #97b7d7;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row1_col5,#T_34105_row2_col4{\n",
       "            background-color:  #f3edf5;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row1_col6,#T_34105_row6_col1{\n",
       "            background-color:  #b8c6e0;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row1_col8{\n",
       "            background-color:  #e2dfee;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row2_col0,#T_34105_row5_col0,#T_34105_row5_col3{\n",
       "            background-color:  #bdc8e1;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row2_col1,#T_34105_row6_col0,#T_34105_row7_col0,#T_34105_row7_col1{\n",
       "            background-color:  #d0d1e6;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row2_col3{\n",
       "            background-color:  #fbf3f9;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row2_col6{\n",
       "            background-color:  #80aed2;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row2_col8{\n",
       "            background-color:  #529bc7;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row3_col0,#T_34105_row7_col3{\n",
       "            background-color:  #a7bddb;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row3_col1{\n",
       "            background-color:  #f5eff6;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row3_col2,#T_34105_row7_col2{\n",
       "            background-color:  #fef6fa;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row3_col4{\n",
       "            background-color:  #c4cbe3;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row3_col5,#T_34105_row5_col7{\n",
       "            background-color:  #dcdaeb;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row3_col7{\n",
       "            background-color:  #adc1dd;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row3_col8,#T_34105_row4_col7{\n",
       "            background-color:  #d9d8ea;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row4_col0{\n",
       "            background-color:  #f4eef6;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row4_col3{\n",
       "            background-color:  #d2d3e7;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row4_col5{\n",
       "            background-color:  #fdf5fa;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row5_col1{\n",
       "            background-color:  #ced0e6;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row5_col2{\n",
       "            background-color:  #ede8f3;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row5_col4,#T_34105_row6_col7{\n",
       "            background-color:  #dbdaeb;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row5_col6{\n",
       "            background-color:  #c0c9e2;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row5_col8{\n",
       "            background-color:  #e8e4f0;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row6_col2{\n",
       "            background-color:  #93b5d6;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row6_col3,#T_34105_row6_col5{\n",
       "            background-color:  #eae6f1;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row6_col8{\n",
       "            background-color:  #bfc9e1;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row7_col4{\n",
       "            background-color:  #c5cce3;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row7_col5{\n",
       "            background-color:  #f0eaf4;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row7_col6{\n",
       "            background-color:  #c8cde4;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row7_col8{\n",
       "            background-color:  #d6d6e9;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row8_col0{\n",
       "            background-color:  #c6cce3;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row8_col1{\n",
       "            background-color:  #cdd0e5;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row8_col2{\n",
       "            background-color:  #4c99c5;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row8_col4{\n",
       "            background-color:  #efe9f3;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row8_col5{\n",
       "            background-color:  #f7f0f7;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row8_col6{\n",
       "            background-color:  #a5bddb;\n",
       "            color:  #000000;\n",
       "        }#T_34105_row8_col7{\n",
       "            background-color:  #d3d4e7;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_34105_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >track_id</th>        <th class=\"col_heading level0 col1\" >acousticness</th>        <th class=\"col_heading level0 col2\" >danceability</th>        <th class=\"col_heading level0 col3\" >energy</th>        <th class=\"col_heading level0 col4\" >instrumentalness</th>        <th class=\"col_heading level0 col5\" >liveness</th>        <th class=\"col_heading level0 col6\" >speechiness</th>        <th class=\"col_heading level0 col7\" >tempo</th>        <th class=\"col_heading level0 col8\" >valence</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_34105_level0_row0\" class=\"row_heading level0 row0\" >track_id</th>\n",
       "                        <td id=\"T_34105_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "                        <td id=\"T_34105_row0_col1\" class=\"data row0 col1\" >-0.372282</td>\n",
       "                        <td id=\"T_34105_row0_col2\" class=\"data row0 col2\" >0.049454</td>\n",
       "                        <td id=\"T_34105_row0_col3\" class=\"data row0 col3\" >0.140703</td>\n",
       "                        <td id=\"T_34105_row0_col4\" class=\"data row0 col4\" >-0.275623</td>\n",
       "                        <td id=\"T_34105_row0_col5\" class=\"data row0 col5\" >0.048231</td>\n",
       "                        <td id=\"T_34105_row0_col6\" class=\"data row0 col6\" >-0.026995</td>\n",
       "                        <td id=\"T_34105_row0_col7\" class=\"data row0 col7\" >-0.025392</td>\n",
       "                        <td id=\"T_34105_row0_col8\" class=\"data row0 col8\" >0.010070</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_34105_level0_row1\" class=\"row_heading level0 row1\" >acousticness</th>\n",
       "                        <td id=\"T_34105_row1_col0\" class=\"data row1 col0\" >-0.372282</td>\n",
       "                        <td id=\"T_34105_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "                        <td id=\"T_34105_row1_col2\" class=\"data row1 col2\" >-0.028954</td>\n",
       "                        <td id=\"T_34105_row1_col3\" class=\"data row1 col3\" >-0.281619</td>\n",
       "                        <td id=\"T_34105_row1_col4\" class=\"data row1 col4\" >0.194780</td>\n",
       "                        <td id=\"T_34105_row1_col5\" class=\"data row1 col5\" >-0.019991</td>\n",
       "                        <td id=\"T_34105_row1_col6\" class=\"data row1 col6\" >0.072204</td>\n",
       "                        <td id=\"T_34105_row1_col7\" class=\"data row1 col7\" >-0.026310</td>\n",
       "                        <td id=\"T_34105_row1_col8\" class=\"data row1 col8\" >-0.013841</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_34105_level0_row2\" class=\"row_heading level0 row2\" >danceability</th>\n",
       "                        <td id=\"T_34105_row2_col0\" class=\"data row2 col0\" >0.049454</td>\n",
       "                        <td id=\"T_34105_row2_col1\" class=\"data row2 col1\" >-0.028954</td>\n",
       "                        <td id=\"T_34105_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "                        <td id=\"T_34105_row2_col3\" class=\"data row2 col3\" >-0.242032</td>\n",
       "                        <td id=\"T_34105_row2_col4\" class=\"data row2 col4\" >-0.255217</td>\n",
       "                        <td id=\"T_34105_row2_col5\" class=\"data row2 col5\" >-0.106584</td>\n",
       "                        <td id=\"T_34105_row2_col6\" class=\"data row2 col6\" >0.276206</td>\n",
       "                        <td id=\"T_34105_row2_col7\" class=\"data row2 col7\" >-0.242089</td>\n",
       "                        <td id=\"T_34105_row2_col8\" class=\"data row2 col8\" >0.473165</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_34105_level0_row3\" class=\"row_heading level0 row3\" >energy</th>\n",
       "                        <td id=\"T_34105_row3_col0\" class=\"data row3 col0\" >0.140703</td>\n",
       "                        <td id=\"T_34105_row3_col1\" class=\"data row3 col1\" >-0.281619</td>\n",
       "                        <td id=\"T_34105_row3_col2\" class=\"data row3 col2\" >-0.242032</td>\n",
       "                        <td id=\"T_34105_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "                        <td id=\"T_34105_row3_col4\" class=\"data row3 col4\" >0.028238</td>\n",
       "                        <td id=\"T_34105_row3_col5\" class=\"data row3 col5\" >0.113331</td>\n",
       "                        <td id=\"T_34105_row3_col6\" class=\"data row3 col6\" >-0.109983</td>\n",
       "                        <td id=\"T_34105_row3_col7\" class=\"data row3 col7\" >0.195227</td>\n",
       "                        <td id=\"T_34105_row3_col8\" class=\"data row3 col8\" >0.038603</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_34105_level0_row4\" class=\"row_heading level0 row4\" >instrumentalness</th>\n",
       "                        <td id=\"T_34105_row4_col0\" class=\"data row4 col0\" >-0.275623</td>\n",
       "                        <td id=\"T_34105_row4_col1\" class=\"data row4 col1\" >0.194780</td>\n",
       "                        <td id=\"T_34105_row4_col2\" class=\"data row4 col2\" >-0.255217</td>\n",
       "                        <td id=\"T_34105_row4_col3\" class=\"data row4 col3\" >0.028238</td>\n",
       "                        <td id=\"T_34105_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "                        <td id=\"T_34105_row4_col5\" class=\"data row4 col5\" >-0.091022</td>\n",
       "                        <td id=\"T_34105_row4_col6\" class=\"data row4 col6\" >-0.366762</td>\n",
       "                        <td id=\"T_34105_row4_col7\" class=\"data row4 col7\" >0.022215</td>\n",
       "                        <td id=\"T_34105_row4_col8\" class=\"data row4 col8\" >-0.219967</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_34105_level0_row5\" class=\"row_heading level0 row5\" >liveness</th>\n",
       "                        <td id=\"T_34105_row5_col0\" class=\"data row5 col0\" >0.048231</td>\n",
       "                        <td id=\"T_34105_row5_col1\" class=\"data row5 col1\" >-0.019991</td>\n",
       "                        <td id=\"T_34105_row5_col2\" class=\"data row5 col2\" >-0.106584</td>\n",
       "                        <td id=\"T_34105_row5_col3\" class=\"data row5 col3\" >0.113331</td>\n",
       "                        <td id=\"T_34105_row5_col4\" class=\"data row5 col4\" >-0.091022</td>\n",
       "                        <td id=\"T_34105_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "                        <td id=\"T_34105_row5_col6\" class=\"data row5 col6\" >0.041173</td>\n",
       "                        <td id=\"T_34105_row5_col7\" class=\"data row5 col7\" >0.002732</td>\n",
       "                        <td id=\"T_34105_row5_col8\" class=\"data row5 col8\" >-0.045093</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_34105_level0_row6\" class=\"row_heading level0 row6\" >speechiness</th>\n",
       "                        <td id=\"T_34105_row6_col0\" class=\"data row6 col0\" >-0.026995</td>\n",
       "                        <td id=\"T_34105_row6_col1\" class=\"data row6 col1\" >0.072204</td>\n",
       "                        <td id=\"T_34105_row6_col2\" class=\"data row6 col2\" >0.276206</td>\n",
       "                        <td id=\"T_34105_row6_col3\" class=\"data row6 col3\" >-0.109983</td>\n",
       "                        <td id=\"T_34105_row6_col4\" class=\"data row6 col4\" >-0.366762</td>\n",
       "                        <td id=\"T_34105_row6_col5\" class=\"data row6 col5\" >0.041173</td>\n",
       "                        <td id=\"T_34105_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "                        <td id=\"T_34105_row6_col7\" class=\"data row6 col7\" >0.008241</td>\n",
       "                        <td id=\"T_34105_row6_col8\" class=\"data row6 col8\" >0.149894</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_34105_level0_row7\" class=\"row_heading level0 row7\" >tempo</th>\n",
       "                        <td id=\"T_34105_row7_col0\" class=\"data row7 col0\" >-0.025392</td>\n",
       "                        <td id=\"T_34105_row7_col1\" class=\"data row7 col1\" >-0.026310</td>\n",
       "                        <td id=\"T_34105_row7_col2\" class=\"data row7 col2\" >-0.242089</td>\n",
       "                        <td id=\"T_34105_row7_col3\" class=\"data row7 col3\" >0.195227</td>\n",
       "                        <td id=\"T_34105_row7_col4\" class=\"data row7 col4\" >0.022215</td>\n",
       "                        <td id=\"T_34105_row7_col5\" class=\"data row7 col5\" >0.002732</td>\n",
       "                        <td id=\"T_34105_row7_col6\" class=\"data row7 col6\" >0.008241</td>\n",
       "                        <td id=\"T_34105_row7_col7\" class=\"data row7 col7\" >1.000000</td>\n",
       "                        <td id=\"T_34105_row7_col8\" class=\"data row7 col8\" >0.052221</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_34105_level0_row8\" class=\"row_heading level0 row8\" >valence</th>\n",
       "                        <td id=\"T_34105_row8_col0\" class=\"data row8 col0\" >0.010070</td>\n",
       "                        <td id=\"T_34105_row8_col1\" class=\"data row8 col1\" >-0.013841</td>\n",
       "                        <td id=\"T_34105_row8_col2\" class=\"data row8 col2\" >0.473165</td>\n",
       "                        <td id=\"T_34105_row8_col3\" class=\"data row8 col3\" >0.038603</td>\n",
       "                        <td id=\"T_34105_row8_col4\" class=\"data row8 col4\" >-0.219967</td>\n",
       "                        <td id=\"T_34105_row8_col5\" class=\"data row8 col5\" >-0.045093</td>\n",
       "                        <td id=\"T_34105_row8_col6\" class=\"data row8 col6\" >0.149894</td>\n",
       "                        <td id=\"T_34105_row8_col7\" class=\"data row8 col7\" >0.052221</td>\n",
       "                        <td id=\"T_34105_row8_col8\" class=\"data row8 col8\" >1.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff23805c1c0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a correlation matrix\n",
    "corr_metrics = echo_tracks.corr()\n",
    "corr_metrics.style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "17"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## Splitting the data\n",
    "<p>In order to improve the performance of our model, we want to use as few features as possible while still achieving good results. We previously analyzed the correlations between the features and did not find any particularly strong ones. Now we can split our data into two arrays: one containing the features and another containing the labels (the genre of the track).</p>\n",
    "<p>Before building the model, we will perform some preprocessing steps to optimize the data for modeling. These steps will help improve the accuracy and efficiency of our model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "dc": {
     "key": "17"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Import train_test_split function and Decision tree classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create features\n",
    "features = echo_tracks.drop([\"genre_top\", \"track_id\"], axis=1).values\n",
    "\n",
    "# Create labels\n",
    "labels = echo_tracks[\"genre_top\"].values\n",
    "\n",
    "# Split our data, we keep test_size = 0.25 (as it is by default)\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "dc": {
     "key": "17"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.48677459e-01, 1.37199242e-01, 2.47403596e-02],\n",
       "       [1.02727000e-05, 1.18115308e-01, 7.50281301e-01],\n",
       "       [3.12262570e-02, 6.28698289e-01, 8.31143855e-01]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.70243534, 0.4144095 , 0.2179091 ],\n",
       "       [0.18201668, 0.5798426 , 0.32738372],\n",
       "       [0.84948   , 0.60548623, 0.31545322]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(train_features[:3, :3])\n",
    "test_features[:3, :3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "24"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## Scaling the features\n",
    "<p>To simplify our model and use as few features as possible while still achieving good results, we can apply a technique called <strong>principal component analysis (PCA)</strong>.</p>\n",
    "<p>PCA works by rotating the data along the axis of highest variance, which allows us to determine the relative contribution of each feature to the variance between classes. However, it's important to note that PCA uses the absolute variance of a feature to rotate the data, so a feature with a broader range of values may overpower and bias the algorithm relative to the other features.</p>\n",
    "\n",
    "<p>To prevent this, we will normalize our train and test features using a method called <em>standardization</em>. This involves transforming the data so that all features have a mean of 0 and a standard deviation of 1 (resulting in a z-score).</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "dc": {
     "key": "24"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale train_features and test_features\n",
    "scaled_train_features = scaler.fit_transform(train_features)\n",
    "scaled_test_features = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "dc": {
     "key": "24"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.24994743, -1.64927931, -2.45820448],\n",
       "       [-1.33744998, -1.75457157,  0.5134387 ],\n",
       "       [-1.25231142,  1.06248053,  0.8446325 ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0033314763549054556"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9978729657625621"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.57834602, -0.11982028, -1.66703124],\n",
       "       [-0.84104522,  0.79292784, -1.21864922],\n",
       "       [ 0.97939601,  0.93441209, -1.26751374]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(scaled_train_features[:3, :3])\n",
    "display(scaled_test_features[:, 2].mean())\n",
    "display(scaled_test_features[:, 2].std())\n",
    "scaled_test_features[:3, :3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "31"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## Applying PCA to scaled data\n",
    "<p>Now that we have preprocessed our data, we can use PCA to determine how much we can reduce the dimensionality of the data. To help us find the optimal number of components to use, we can use two tools: <strong>scree plots</strong> and <strong>cumulative explained ratio plots</strong>.</p>\n",
    "<p>Scree plots show the number of components on the x-axis and the variance explained by each component on the y-axis, with the components sorted in descending order of variance. These plots can help us understand which components contribute the most to the variance in our data. When interpreting a scree plot, we often look for an \"elbow\" (a steep drop from one data point to the next) to determine the appropriate cutoff for the number of components to use. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "dc": {
     "key": "31"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Principal Component #')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This allows plots to appear in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Import plotting module and PCA class\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Get explained variance ratios from PCA using all features\n",
    "pca = PCA()\n",
    "pca.fit(scaled_train_features)\n",
    "exp_variance = pca.explained_variance_ratio_\n",
    "\n",
    "# Plot explained variance using barplot\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(range(pca.n_components_), exp_variance)\n",
    "ax.set_xlabel('Principal Component #')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "dc": {
     "key": "31"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23895983, 0.18149129, 0.13648392, 0.13004899, 0.1124591 ,\n",
       "       0.08329047, 0.07040829, 0.04685811])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "38"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## Further visualization of PCA\n",
    "<p>If the scree plot does not show a clear elbow, it may be difficult to determine the optimal number of intrinsic dimensions using this method. However, we can also use a <strong>cumulative explained variance plot</strong> to help us decide on the number of features to use.</p>\n",
    "<p>This plot shows the cumulative variance explained by the components, and we can choose a cutoff (such as explaining 85% of the variance) to determine the appropriate number of components. </p>\n",
    "<p>Once we determine that, we can perform PCA with that many components, ideally reducing the dimensionality of our data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "dc": {
     "key": "38"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7ff238060fd0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Calculate cumulative explained variance\n",
    "cum_exp_variance = np.cumsum(exp_variance)\n",
    "\n",
    "# Plot cumulative explained variance and draw dashed line at 0.85\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(pca.n_components_), cum_exp_variance)\n",
    "ax.axhline(y=0.85, linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "45"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## Reducing dimensions using PCA\n",
    "<p>After analyzing the cumulative explained variance plot, we determined that using 6 components can explain approximately 85% of the variance in our data. </p>\n",
    "<p>Based on this information, we will use 6 components in our PCA analysis to reduce the dimensionality of our train and test features.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "dc": {
     "key": "45"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Perform PCA with 6 components\n",
    "pca = PCA(n_components=6, random_state=10)\n",
    "\n",
    "# Fit and transform scaled training features using pca\n",
    "train_pca = pca.fit_transform(scaled_train_features)\n",
    "\n",
    "# Transform scaled test features using pca\n",
    "test_pca = pca.transform(scaled_test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "52"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## Training a decision tree classifier\n",
    "<p>Now that we have reduced the dimensionality of our data using PCA, we can use this lower-dimensional projection to classify songs into genres. To do this, we will use a simple and intuitive machine learning algorithm called a <strong>decision tree</strong>.</p>\n",
    "<p>Decision trees are rule-based classifiers that use a tree structure of binary decisions to classify data points into one of two or more categories.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "dc": {
     "key": "52"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create DecisionTreeClassifier object\n",
    "tree = DecisionTreeClassifier(random_state=10)\n",
    "\n",
    "# Train decision tree\n",
    "tree.fit(train_pca, train_labels)\n",
    "\n",
    "# Predict labels for test data\n",
    "pred_labels_tree = tree.predict(test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "59"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## Comparing decision tree to logistic regression\n",
    "<p>Although our decision tree is performing well, it's always a good idea to try out other algorithms to see if we can find one that performs even better. One option is <strong>logistic regression</strong>, which uses the logistic function to calculate the odds that a given data point belongs to a particular class. </p>\n",
    "<p>By comparing the performance of our decision tree and logistic regression models using metrics such as the false positive and false negative rates (which measure the number of inaccurately classified points), we can choose the model that performs best on our data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "dc": {
     "key": "59"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Hip-Hop       0.63      0.62      0.62       235\n",
      "        Rock       0.91      0.91      0.91       966\n",
      "\n",
      "    accuracy                           0.85      1201\n",
      "   macro avg       0.77      0.77      0.77      1201\n",
      "weighted avg       0.85      0.85      0.85      1201\n",
      "\n",
      "Logistic Regression: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Hip-Hop       0.77      0.54      0.64       235\n",
      "        Rock       0.90      0.96      0.93       966\n",
      "\n",
      "    accuracy                           0.88      1201\n",
      "   macro avg       0.83      0.75      0.78      1201\n",
      "weighted avg       0.87      0.88      0.87      1201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create LogisticRegression object\n",
    "logreg = LogisticRegression(random_state=10)\n",
    "\n",
    "# Train logistic regression and predict labels for test set\n",
    "logreg.fit(train_pca, train_labels)\n",
    "pred_labels_logit = logreg.predict(test_pca)\n",
    "\n",
    "# Import classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate classification reports for decision tree and logistic regression models\n",
    "class_rep_tree = classification_report(test_labels, pred_labels_tree)\n",
    "class_rep_log = classification_report(test_labels, pred_labels_logit)\n",
    "\n",
    "# Print classification reports\n",
    "print(\"Decision Tree: \\n\", class_rep_tree)\n",
    "print(\"Logistic Regression: \\n\", class_rep_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "66"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## Balancing the data for improved performance\n",
    "<p>Both our decision tree and logistic regression models have an average precision of 85% and 87%. However, examining the classification report shows that the models disproportionately misclassify hip-hop songs as rock songs. </p>\n",
    "<p>One possible reason for this is the imbalanced number of data points for each class. We have significantly more data points for the rock class than for the hip-hop class, which could be skewing the model's ability to distinguish between the two classes. As a result, most of the model's accuracy is driven by its ability to classify rock songs, rather than a balanced performance across all classes. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "dc": {
     "key": "66"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Subset hip-hop and rock tracks\n",
    "hop_only = echo_tracks[echo_tracks['genre_top'] == 'Hip-Hop']\n",
    "rock_only = echo_tracks[echo_tracks['genre_top'] == 'Rock']\n",
    "\n",
    "# Sample rock songs to have same number as hip-hop songs\n",
    "rock_only = rock_only.sample(n=len(hop_only), random_state=10)\n",
    "\n",
    "# Concatenate hip-hop and rock tracks to create balanced dataset\n",
    "rock_hop_bal = pd.concat([rock_only, hop_only])\n",
    "\n",
    "# Create features and labels from balanced dataset\n",
    "features = rock_hop_bal.drop(['genre_top', 'track_id'], axis=1) \n",
    "labels = rock_hop_bal['genre_top']\n",
    "\n",
    "# Split data into train and test sets, and then transform\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, random_state=10)\n",
    "\n",
    "train_pca = pca.fit_transform(scaler.fit_transform(train_features))\n",
    "test_pca = pca.transform(scaler.transform(test_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "73"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## Assessing the impact of balanced data on model bias\n",
    "<p>We have balanced our dataset by accounting for the imbalanced number of data points for each class. Now, we want to test whether balancing the data improves the model's bias towards the \"Rock\" classification while still maintaining overall classification performance. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "dc": {
     "key": "73"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Hip-Hop       0.82      0.77      0.79       230\n",
      "        Rock       0.78      0.82      0.80       225\n",
      "\n",
      "    accuracy                           0.80       455\n",
      "   macro avg       0.80      0.80      0.80       455\n",
      "weighted avg       0.80      0.80      0.80       455\n",
      "\n",
      "Logistic Regression: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Hip-Hop       0.84      0.80      0.82       230\n",
      "        Rock       0.81      0.85      0.83       225\n",
      "\n",
      "    accuracy                           0.82       455\n",
      "   macro avg       0.82      0.82      0.82       455\n",
      "weighted avg       0.83      0.82      0.82       455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train decision tree and logistic regression on balanced data\n",
    "tree = DecisionTreeClassifier(random_state=10)\n",
    "logreg = LogisticRegression(random_state=10)\n",
    "\n",
    "tree.fit(train_pca, train_labels)\n",
    "logreg.fit(train_pca, train_labels)\n",
    "\n",
    "pred_labels_tree = tree.predict(test_pca)\n",
    "pred_labels_logit = logreg.predict(test_pca)\n",
    "\n",
    "# Compare models with classification report\n",
    "print(\"Decision Tree: \\n\", classification_report(test_labels, pred_labels_tree))\n",
    "print(\"Logistic Regression: \\n\", classification_report(test_labels, pred_labels_logit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "80"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## Evaluating models using cross-validation\n",
    "<p>Balancing our data has successfully removed the bias towards the more prevalent class. To more accurately evaluate the performance of our models, we can use a technique called <strong>cross-validation</strong> (CV). </p>\n",
    "<p>Before we can perform cross-validation, we need to create pipelines to scale our data, apply PCA, and instantiate our chosen models (<code>DecisionTreeClassifier</code> and <code>LogisticRegression</code>). Cross-validation is useful because the way that the data is split into train and test sets can affect model performance. CV attempts to split the data multiple ways and test the model on each split to mitigate this issue. </p>\n",
    "<p>One common method of cross-validation is <strong>K-fold</strong> CV, which divides the data into K equally sized subsets. The model is then trained and tested on each subset, and the results are aggregated to obtain a final model performance score.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "dc": {
     "key": "80"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree : 0.76\n",
      "Logistic Regression: 0.78\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# Create pipelines for Decision Tree and Logistic Regression\n",
    "tree_pipe = Pipeline([(\"scaler\", StandardScaler()), \n",
    "                      (\"pca\", PCA(n_components=6)), \n",
    "                      (\"tree\", DecisionTreeClassifier(random_state=10))])\n",
    "logreg_pipe = Pipeline([(\"scaler\", StandardScaler()), \n",
    "                        (\"pca\", PCA(n_components=6)), \n",
    "                        (\"logreg\", LogisticRegression(random_state=10))])\n",
    "\n",
    "# Use KFold cross-validation with 10 splits\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "# Train models with cross-validation\n",
    "tree_score = cross_val_score(tree_pipe, features, labels, cv=kf)\n",
    "logit_score = cross_val_score(logreg_pipe, features, labels, cv=kf)\n",
    "\n",
    "# Print mean and standard deviation of scores\n",
    "print(\"Decision Tree :\", round(tree_score.mean(), 2))\n",
    "print(\"Logistic Regression:\", round(logit_score.mean(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "<p>In this project, we analyzed a dataset of songs and their associated genres and developed machine learning models to classify songs into their respective genres. We compared the performance of decision tree and logistic regression models using K-fold cross-validation and found that the <code>logistic regression</code> model had a mean accuracy of <strong>78%</strong>, while the <code>decision tree</code> model had a mean accuracy of <strong>76%</strong>.</p>\n",
    "<p>Overall, both models performed well on the dataset, but the logistic regression model was slightly more accurate.</p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
